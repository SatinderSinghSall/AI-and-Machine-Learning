{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d5c0d6-3f1e-456b-92d0-7fbfb45fef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6f57b6-3033-4fac-bf61-5b60d2b4ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets & DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
    "testset = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3b592a-e55f-4b54-b0e2-893bef1860c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd29a9d-b1ad-408d-8860-6fd62ecf3b00",
   "metadata": {},
   "source": [
    "### Build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b61ab3-5a4e-4aba-87c8-81d247fd0fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # kernel size = 2, stride = 2\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2) ,\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(4*4*128, 256),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1) # flattening\n",
    "        x = self.fc_layers(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3811d0e9-3d66-46b0-8274-684e0c588859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54647803-1c65-4472-9445-608cd5e97a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842569e1-6c1b-4786-b28a-2c713f8db4cb",
   "metadata": {},
   "source": [
    "### Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5ea7457-6495-4bbc-8d74-64026f5fb2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1/10 & loss=0.7555867616477829\n",
      "epoch=2/10 & loss=0.6321544994402419\n",
      "epoch=3/10 & loss=0.5293124040679249\n",
      "epoch=4/10 & loss=0.4282203432353561\n",
      "epoch=5/10 & loss=0.34689718728785013\n",
      "epoch=6/10 & loss=0.27911227575653347\n",
      "epoch=7/10 & loss=0.21182899593430407\n",
      "epoch=8/10 & loss=0.17249419825518375\n",
      "epoch=9/10 & loss=0.13504543231890712\n",
      "epoch=10/10 & loss=0.11345219289612435\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_training_loss = 0.0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images) # FP\n",
    "        loss = criterion(output, labels) # loss fnx\n",
    "        loss.backward() # BP\n",
    "        optimizer.step() # update params\n",
    "\n",
    "        epoch_training_loss += loss.item()\n",
    "\n",
    "    print(f\"epoch={epoch+1}/{epochs} & loss={epoch_training_loss/len(trainloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca58a45-8ae4-41c4-b4d1-a552400abc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 74.71\n"
     ]
    }
   ],
   "source": [
    "# Evaludate our CNN\n",
    "\n",
    "correct_labels = 0\n",
    "total_labels = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        outputs = model.forward(images)\n",
    "        _, predicted  = torch.max(outputs, 1)\n",
    "\n",
    "        correct_labels += (predicted == labels).sum().item()\n",
    "        total_labels += labels.size(0)\n",
    "\n",
    "print(f\"accuracy = {correct_labels / total_labels * 100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f8c800-b366-4262-909b-7fd3b8834559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
