


import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from torch.utils.data import TensorDataset, DataLoader
import torch.optim as optim





df = pd.read_csv("powerplant_data.csv")


df.head()





df.isnull().sum()





X = df.drop("PE", axis = 1) # Features
y = df["PE"] # Labels


X.head()# Features


y.head() # Labels





X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size = 0.2,
    random_state = 42
)


X_train


X_test


y_train


y_test


df.shape





scaler = StandardScaler()

X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


X_train_scaled


X_test_scaled





X_train_tensor = torch.tensor(X_train_scaled, dtype = torch.float32)
y_train_tensor = torch.tensor(y_train.values, dtype = torch.float32).view(-1, 1)

X_test_tensor = torch.tensor(X_test_scaled, dtype = torch.float32)
y_test_tensor = torch.tensor(y_test.values, dtype = torch.float32).view(-1, 1)


type(X_train_scaled)


type(y_train)


y_train.shape


y_train





train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
test_dataset = TensorDataset(X_test_tensor, y_test_tensor)





train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True)
test_loader = DataLoader(test_dataset, batch_size = 32)





class ANN(nn.Module):
    def __init__(self):
        super(ANN, self).__init__()

        self.model = nn.Sequential(
            # 1st hidden layer:
            nn.Linear(X_train.shape[1], 6),
            nn.ReLU(),
    
            # 2nd hidden layer:
            nn.Linear(6, 6),
            nn.ReLU(),
    
            # Output layer:
            nn.Linear(6, 1)
        )

    # Forward Propagation:
    def forword(self, x):
        return self.model(x)





model = ANN()

# loss, optimiser
crietian = nn.MSELoss()
optimiser = optim.Adam(model.parameters())


model









