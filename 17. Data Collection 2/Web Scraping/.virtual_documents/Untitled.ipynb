





import requests


URL = "https://www.scrapethissite.com/pages/simple/"

res = requests.get(URL)

print(res.status_code)


if res.status_code == 200:
    print(res.content)

with open("scraped_data/data1.html", "w", encoding="utf-8") as f:
    f.write(res.text)





from bs4 import BeautifulSoup


with open("scraped_data/data1.html", "r") as f:
    html_content = f.read()
soup = BeautifulSoup(html_content, "lxml")


soup





all_h3 = soup.find_all("h3")
all_countries = []

for h3 in all_h3:
    name = h3.get_text(strip=True)
    # print(h3.find_parent("div")["class"])
    population = h3.find_next("div").select("span.country-population")[0].get_text(strip=True)
    print(h3.find_next("div").select("span.country-population")[0].get_text(strip=True))
    all_countries.append([name, population])



all_countries





import pandas as pd

pd.DataFrame(all_countries, columns=["Name", "Population"])


df.to_csv("cleaned_data/data.csv", index=False)



